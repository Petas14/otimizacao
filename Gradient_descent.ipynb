{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradiente Descendente\n",
    "\n",
    "\n",
    "## A ideia geral do algoritmo é relaticamente simples, dado um mátrica a ser minimzada, iremos tomar sua derivada, que representa a taxa de variação, e iremos empregar esta, atualoizando os parâmetros do modelo, até que tal derivada seja nula.\n",
    "\n",
    "## Suponto uma variável $w$, iremos o atualizar de acordo com\n",
    "\n",
    "## $w_i = w{i-1} - \\alpha \\frac{dL}{dw} $\n",
    "\n",
    "## Em que L é a métrica de erro, pode ser o erro quadrático ou o erro absoluto, erro quadrático médio. Em geral não é \"tão importante\", as vezes a escolha de uma métrica específica pode ajudar.\n",
    "\n",
    "## No exemplo abaixo, iremos encontrar pos parametros de uma simples função quadrática usando tal método.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "class gradient:\n",
    "    def __init__(self,f,w,dw,batch=20,max_iter = 10000,lr = 0.00000001):\n",
    "        self.lr = lr\n",
    "        self.w = w\n",
    "        self.dw = dw\n",
    "        self.batch = batch\n",
    "        self.max_iter = max_iter\n",
    "        self.f = f\n",
    "\n",
    "\n",
    "    def fit(self,X,y):\n",
    "        int_per_batch = int(len(X)/self.batch)\n",
    "        for _ in range(self.max_iter):\n",
    "            for j in range(int_per_batch):\n",
    "                yhat = self.f(X[j*self.batch:(j+1)*self.batch],w)\n",
    "                loss = np.mean((y[j*self.batch:(j+1)*self.batch] - yhat)**2)\n",
    "                dw = np.float64((y[j*self.batch:(j+1)*self.batch] -yhat).T @ self.dw(X[j*self.batch:(j+1)*self.batch])).T\n",
    "                self.w += self.lr*dw\n",
    "        return self.w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda x,w: x @ w \n",
    "\n",
    "dw = lambda x: x\n",
    "\n",
    "w = np.random.normal(0,1,(2,1))\n",
    "\n",
    "X = np.arange(1,1000).reshape(-1,1)\n",
    "\n",
    "y = 5*X + 1 \n",
    "\n",
    "X_in = np.append(X,np.ones(X.shape),axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5.00242736]\n",
      " [-1.054303  ]]\n",
      "[[ 5.00180223]\n",
      " [-0.76660331]]\n"
     ]
    }
   ],
   "source": [
    "grad = gradient(f,w,dw)\n",
    "w = grad.fit(X_in,y)\n",
    "print(w)\n",
    "grad = gradient(f,w,dw,lr = 0.0000001)\n",
    "w = grad.fit(X_in,y)\n",
    "print(w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
